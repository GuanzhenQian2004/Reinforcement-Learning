{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Necessary libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a93c2df880156f5f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-04T02:22:46.156479Z",
     "start_time": "2024-11-04T02:22:46.150890Z"
    }
   },
   "id": "73b6742b47c408d7",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the actions and simulation parameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8f843ab908e7fd7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Constants representing actions\n",
    "ACTION_BACK = 0\n",
    "ACTION_END = 1\n",
    "\n",
    "# Simulation parameters\n",
    "RUNS = 10\n",
    "EPISODES = 10 ** 6"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-04T02:22:46.189133Z",
     "start_time": "2024-11-04T02:22:46.185491Z"
    }
   },
   "id": "b5856fd834ae961d",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create the Agent and Environment classes to encapsulate the agent's policies and the environment's dynamics."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2dca14cd0e2a26f8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def behavior_policy(self):\n",
    "        # Randomly choose ACTION_BACK or ACTION_END with equal probability\n",
    "        return np.random.choice([ACTION_BACK, ACTION_END])\n",
    "\n",
    "    def target_policy(self):\n",
    "        # Always choose ACTION_BACK\n",
    "        return ACTION_BACK"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-04T02:22:46.197523Z",
     "start_time": "2024-11-04T02:22:46.190140Z"
    }
   },
   "id": "48349d7f79fecd5e",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    def step(self, action):\n",
    "        # If the action is ACTION_END, the episode ends without reward\n",
    "        if action == ACTION_END:\n",
    "            return 0, True\n",
    "        # With 10% probability, receive a reward and end the episode\n",
    "        if np.random.rand() < 0.1:\n",
    "            return 1, True\n",
    "        else:\n",
    "            # Continue the episode without reward\n",
    "            return 0, False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-04T02:22:46.204720Z",
     "start_time": "2024-11-04T02:22:46.199530Z"
    }
   },
   "id": "612cca8e96595097",
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define helper functions for computing the importance sampling ratio and simulating episodes."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "996eacb92b878766"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def compute_importance_ratio(trajectory):\n",
    "    # If ACTION_END is in the trajectory, the target policy probability is zero\n",
    "    if ACTION_END in trajectory:\n",
    "        return 0\n",
    "    # Importance ratio is (1/0.5)^len(trajectory) = 2^len(trajectory)\n",
    "    return 2 ** len(trajectory)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-04T02:22:46.214703Z",
     "start_time": "2024-11-04T02:22:46.205728Z"
    }
   },
   "id": "ee23a0c1bf1f167e",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def simulate_episode(agent, env):\n",
    "    trajectory = []\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = agent.behavior_policy()\n",
    "        trajectory.append(action)\n",
    "        reward, done = env.step(action)\n",
    "    rho = compute_importance_ratio(trajectory)\n",
    "    return reward, trajectory, rho"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-04T02:22:46.224753Z",
     "start_time": "2024-11-04T02:22:46.215711Z"
    }
   },
   "id": "2a72060bf9e468",
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "Implement functions to perform Ordinary Importance Sampling and Weighted Importance Sampling"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b116b39e21189734"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def run_ordinary_importance_sampling(episodes):\n",
    "    rewards = []\n",
    "    for _ in range(episodes):\n",
    "        agent = Agent()\n",
    "        env = Environment()\n",
    "        reward, trajectory, rho = simulate_episode(agent, env)\n",
    "        rewards.append(rho * reward)\n",
    "    cumulative_rewards = np.cumsum(rewards)\n",
    "    estimations = cumulative_rewards / np.arange(1, episodes + 1)\n",
    "    return estimations"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-04T02:22:46.231594Z",
     "start_time": "2024-11-04T02:22:46.226760Z"
    }
   },
   "id": "e2517094475ce589",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def run_weighted_importance_sampling(episodes):\n",
    "    cumulative_reward = 0\n",
    "    cumulative_rho = 0\n",
    "    estimations = []\n",
    "    for _ in range(episodes):\n",
    "        agent = Agent()\n",
    "        env = Environment()\n",
    "        reward, trajectory, rho = simulate_episode(agent, env)\n",
    "        cumulative_reward += rho * reward\n",
    "        cumulative_rho += rho\n",
    "        estimation = cumulative_reward / cumulative_rho if cumulative_rho != 0 else 0\n",
    "        estimations.append(estimation)\n",
    "    return estimations"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-04T02:22:46.240371Z",
     "start_time": "2024-11-04T02:22:46.232600Z"
    }
   },
   "id": "c232f143c223544a",
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create a function to perform the simulations across multiple runs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0268b1ab35d4bb3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def perform_simulation(runs, episodes):\n",
    "    ois_estimations = []\n",
    "    wis_estimations = []\n",
    "    for _ in range(runs):\n",
    "        ois_estimation = run_ordinary_importance_sampling(episodes)\n",
    "        wis_estimation = run_weighted_importance_sampling(episodes)\n",
    "        ois_estimations.append(ois_estimation)\n",
    "        wis_estimations.append(wis_estimation)\n",
    "    return ois_estimations, wis_estimations"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-04T02:22:46.247339Z",
     "start_time": "2024-11-04T02:22:46.242378Z"
    }
   },
   "id": "9073ce2ff66c47e8",
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define a function to plot the estimations from both OIS and WIS with labels"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b039bb29fbdbe88"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def plot_estimations(ois_estimations, wis_estimations, episodes):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    x_values = np.arange(1, episodes + 1)\n",
    "    # Plot OIS estimations\n",
    "    for idx, estimation in enumerate(ois_estimations):\n",
    "        if idx == 0:\n",
    "            plt.plot(x_values, estimation, color='blue', linewidth=1, label='OIS')\n",
    "        else:\n",
    "            plt.plot(x_values, estimation, color='blue', linewidth=1)\n",
    "    # Plot WIS estimations\n",
    "    for idx, estimation in enumerate(wis_estimations):\n",
    "        if idx == 0:\n",
    "            plt.plot(x_values, estimation, color='red', linewidth=1, label='WIS')\n",
    "        else:\n",
    "            plt.plot(x_values, estimation, color='red', linewidth=1)\n",
    "    plt.xlabel('Episodes (log scale)')\n",
    "    plt.ylabel('Importance Sampling Estimates')\n",
    "    plt.xscale('log')\n",
    "    plt.xlim([1, episodes])\n",
    "    plt.legend()\n",
    "    plt.savefig('figure_5_4.png')\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-04T02:22:46.257904Z",
     "start_time": "2024-11-04T02:22:46.250347Z"
    }
   },
   "id": "fc982c0481eff89a",
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run the simulations and plot the results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d47f8c145b80369a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Remote Laptop\\AppData\\Local\\Temp\\ipykernel_24660\\451558836.py:21: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  plt.savefig('figure_5_4.png')\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    ois_estimations, wis_estimations = perform_simulation(RUNS, EPISODES)\n",
    "    plot_estimations(ois_estimations, wis_estimations, EPISODES)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-04T02:26:08.542200Z",
     "start_time": "2024-11-04T02:22:46.259912Z"
    }
   },
   "id": "ba2be5311f0f37b2",
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
