{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Import Necessary Libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "443b600099c1d1b3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Use 'Agg' backend for environments without a display\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.table import Table"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-17T16:52:44.796677Z",
     "start_time": "2024-10-17T16:52:44.792225Z"
    }
   },
   "id": "62d9fa6bb55536ad",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "We define constants used throughout the code here. \n",
    "WORLD_SIZE sets the size of the grid world (4x4)\n",
    "ACTIONS lists the possible actions as numpy arrays.\n",
    "ACTION_PROB assigns equal probability to each action.\n",
    "REWARD is the constant step cost for moving.\n",
    "DISCOUNT is the discount factor for future rewards.\n",
    "OUTPUT_DIR is the directory where images will be saved."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "279297a6a0500f80"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "WORLD_SIZE = 4\n",
    "ACTIONS = [\n",
    "    np.array([0, -1]),  # Left\n",
    "    np.array([-1, 0]),  # Up\n",
    "    np.array([0, 1]),   # Right\n",
    "    np.array([1, 0])    # Down\n",
    "]\n",
    "ACTION_PROB = 0.25  # Equal probability for each action\n",
    "REWARD = -1         # Uniform step cost\n",
    "DISCOUNT = 1.0      # Discount factor\n",
    "OUTPUT_DIR = \"state_value_tables\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-17T16:52:44.817422Z",
     "start_time": "2024-10-17T16:52:44.813684Z"
    }
   },
   "id": "c699ad48bba5ef1f",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "We define the GridWorld class to represent the environment.\n",
    "The init method initializes the grid size, reward, actions, and action probabilities.\n",
    "The is_terminal method checks if a state is terminal.\n",
    "The step method returns the next state and reward after taking an action."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ac3751b9999f81a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class GridWorld:\n",
    "    def __init__(self, size=WORLD_SIZE, reward=REWARD):\n",
    "        self.size = size\n",
    "        self.reward = reward\n",
    "        self.actions = ACTIONS\n",
    "        self.action_prob = ACTION_PROB\n",
    "\n",
    "    def is_terminal(self, state):\n",
    "        # Check if the state is a terminal state\n",
    "        x, y = state\n",
    "        return (x == 0 and y == 0) or (x == self.size - 1 and y == self.size - 1)\n",
    "\n",
    "    def step(self, state, action):\n",
    "        # Execute an action from the current state\n",
    "        if self.is_terminal(state):\n",
    "            return state, 0  # No movement and no reward in terminal states\n",
    "\n",
    "        next_state = np.array(state) + action\n",
    "        x, y = next_state\n",
    "\n",
    "        # If next state is out of bounds, stay in the current state\n",
    "        if x < 0 or x >= self.size or y < 0 or y >= self.size:\n",
    "            next_state = state\n",
    "        else:\n",
    "            next_state = next_state.tolist()\n",
    "\n",
    "        return next_state, self.reward\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-17T16:52:44.826710Z",
     "start_time": "2024-10-17T16:52:44.819427Z"
    }
   },
   "id": "4535e2fe8df90013",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "The PolicyEvaluator class handles the policy evaluation process.\n",
    "The init method sets up the environment, discount factor, and initializes state values.\n",
    "The evaluate_policy method iteratively updates state values until convergence.\n",
    "The policy_evaluation_step method performs one iteration of updates.\n",
    "The compute_state_value method calculates the value for a single state."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "316b7b583a3c4fbd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class PolicyEvaluator:\n",
    "    def __init__(self, environment, discount=DISCOUNT):\n",
    "        self.env = environment\n",
    "        self.discount = discount\n",
    "        self.state_values = np.zeros((self.env.size, self.env.size))\n",
    "\n",
    "    def evaluate_policy(self, desired_iterations):\n",
    "        # Perform iterative policy evaluation\n",
    "        saved_values = {}\n",
    "        iteration = 0\n",
    "\n",
    "        if 0 in desired_iterations:\n",
    "            saved_values[0] = self.state_values.copy()\n",
    "\n",
    "        while True:\n",
    "            delta = self.policy_evaluation_step()\n",
    "            iteration += 1\n",
    "\n",
    "            if iteration in desired_iterations:\n",
    "                saved_values[iteration] = self.state_values.copy()\n",
    "\n",
    "            if delta < 1e-4:\n",
    "                saved_values[iteration] = self.state_values.copy()\n",
    "                print(f'Converged after {iteration} iterations.')\n",
    "                break\n",
    "\n",
    "        return saved_values, iteration\n",
    "\n",
    "    def policy_evaluation_step(self):\n",
    "        # Perform a single iteration of policy evaluation\n",
    "        old_state_values = self.state_values.copy()\n",
    "        delta = 0\n",
    "\n",
    "        for i in range(self.env.size):\n",
    "            for j in range(self.env.size):\n",
    "                if self.env.is_terminal([i, j]):\n",
    "                    continue\n",
    "                value = self.compute_state_value([i, j], old_state_values)\n",
    "                delta = max(delta, abs(value - self.state_values[i, j]))\n",
    "                self.state_values[i, j] = value\n",
    "        return delta\n",
    "\n",
    "    def compute_state_value(self, state, old_state_values):\n",
    "        # Compute the value of a state\n",
    "        value = 0\n",
    "        for action in self.env.actions:\n",
    "            next_state, reward = self.env.step(state, action)\n",
    "            next_i, next_j = next_state\n",
    "            value += self.env.action_prob * (reward + self.discount * old_state_values[next_i, next_j])\n",
    "        return value\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-17T16:52:44.836327Z",
     "start_time": "2024-10-17T16:52:44.828717Z"
    }
   },
   "id": "f56cc6bfb81700cd",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the Function to Draw the State Value Table"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "636cfd373ffe907c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def draw_table(ax, state_values, iteration_label):\n",
    "    ax.set_axis_off()\n",
    "    table = Table(ax, bbox=[0, 0, 1, 1])\n",
    "\n",
    "    nrows, ncols = state_values.shape\n",
    "    width, height = 1.0 / ncols, 1.0 / nrows\n",
    "\n",
    "    # Add cells with state values\n",
    "    for (i, j), val in np.ndenumerate(state_values):\n",
    "        table.add_cell(i, j, width, height, text=f'{val:.1f}',\n",
    "                       loc='center', facecolor='white', edgecolor='black')\n",
    "\n",
    "    ax.add_table(table)\n",
    "    ax.set_title(f'k = {iteration_label}', fontsize=14)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-17T16:52:44.844932Z",
     "start_time": "2024-10-17T16:52:44.838333Z"
    }
   },
   "id": "ed88d41bfe26e8b8",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the Function to Save the State Value Table as an Image"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "834c9ca12dcebe67"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def save_table_image(state_values, iteration_label):\n",
    "    fig, ax = plt.subplots(figsize=(4, 4))\n",
    "    draw_table(ax, state_values, iteration_label)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    # Save the image to the folder\n",
    "    image_path = os.path.join(OUTPUT_DIR, f'state_values_k_{iteration_label}.png')\n",
    "    plt.savefig(image_path)\n",
    "    plt.close()\n",
    "    print(f'Saved state values table for k={iteration_label} to \"{image_path}\".')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-17T16:52:44.852695Z",
     "start_time": "2024-10-17T16:52:44.846938Z"
    }
   },
   "id": "b905da28c5fc25f1",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "Main Execution Flow"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5957ff75d3bfcdb7"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged after 173 iterations.\n",
      "Saved state values table for k=0 to \"state_value_tables\\state_values_k_0.png\".\n",
      "Saved state values table for k=1 to \"state_value_tables\\state_values_k_1.png\".\n",
      "Saved state values table for k=2 to \"state_value_tables\\state_values_k_2.png\".\n",
      "Saved state values table for k=3 to \"state_value_tables\\state_values_k_3.png\".\n",
      "Saved state values table for k=10 to \"state_value_tables\\state_values_k_10.png\".\n",
      "Saved state values table for k=173_converged to \"state_value_tables\\state_values_k_173_converged.png\".\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    desired_iterations = [0, 1, 2, 3, 10]\n",
    "\n",
    "    # Initialize the environment and policy evaluator\n",
    "    environment = GridWorld()\n",
    "    evaluator = PolicyEvaluator(environment)\n",
    "\n",
    "    # Perform policy evaluation\n",
    "    saved_values, convergence_iteration = evaluator.evaluate_policy(desired_iterations)\n",
    "\n",
    "    # Save images for each desired iteration\n",
    "    for iteration in desired_iterations:\n",
    "        save_table_image(saved_values[iteration], iteration)\n",
    "\n",
    "    # Save the final convergence table\n",
    "    save_table_image(saved_values[convergence_iteration], f'{convergence_iteration}_converged')\n",
    "\n",
    "# Execute the main function\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-17T16:52:45.242Z",
     "start_time": "2024-10-17T16:52:44.862209Z"
    }
   },
   "id": "8d249d4f0bad1c06",
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
